### Warnings I've gotten while running this code. Not a current issue but SHould try to fix some of these before December



Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Processing /home/kevius/repos/Data/Sunrise Campus Photos 7-28-25-part-1/Sunrise Campus_072825_AJ_128.jpg
/home/kevius/miniconda3/envs/nightshade/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.
  warnings.warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Processing /home/kevius/repos/Data/Sunrise Campus Photos 7-28-25-part-1/Sunrise Campus_072825_AJ_129.jpg
/home/kevius/miniconda3/envs/nightshade/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.
  warnings.warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
Processing /home/kevius/repos/Data/Sunrise Campus Photos 7-28-25-part-1/Sunrise Campus_072825_AJ_131.jpg
/home/kevius/miniconda3/envs/nightshade/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.
  warnings.warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
Device set to use cuda:0
prepare_a_directory.bash: line 17: unexpected EOF while looking for matching `"'



python3 data_extraction.py --directory ~/repos/Data/Sunrise_captioned  --concept building --num 100 --outdir ~/repos/Data/Sun_Rise_selected
/home/kevius/miniconda3/envs/nightshade/lib/python3.10/site-packages/clip/clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging
Traceback (most recent call last):
  File "/home/kevius/repos/nightshade-release/data_extraction.py", line 136, in <module>
    main()
  File "/home/kevius/repos/nightshade-release/data_extraction.py", line 110, in main
    random_selected_candidate = random.sample(list(candidate), args.num)
  File "/home/kevius/miniconda3/envs/nightshade/lib/python3.10/random.py", line 482, in sample
    raise ValueError("Sample larger than population or is negative")
ValueError: Sample larger than population or is negative


/home/kevius/miniconda3/envs/nightshade/lib/python3.10/site-packages/clip/clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging


Current Limitations
- we can only poison a sample set of images. so lets say we have 100 images we can only poison 45
- image captioning is very slow. SHould be fine for the amout of images we have, but this will have trouble scaling for larger datsets


##current state of ec2 run
[ec2-user@ip-172-31-77-7 ~]$ docker run -it --gpus all   -v ~/.aws:/root/.aws:ro   --name nightshade   782977425966.dkr.ecr.us-east-1.amazonaws.com/nightshade:latest
>>> Downloading images from S3...
>>> Captioning images in batches...
[img_to_pickle] Using device=cuda, dtype=torch.float16, batch_size=8
[img_to_pickle] Found 24 images
`torch_dtype` is deprecated! Use `dtype` instead!
Captioning: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.26batch/s]
>>> Running unsupervised classifier...
Loading images from /app/Data/pickled_images...
Saving classified images to /app/Data/classified_images...
modules.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 349/349 [00:00<00:00, 3.74MB/s]
config_sentence_transformers.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 1.57MB/s]
README.md: 10.5kB [00:00, 32.3MB/s]
sentence_bert_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 754kB/s]
config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 612/612 [00:00<00:00, 9.58MB/s]
model.safetensors: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90.9M/90.9M [00:00<00:00, 199MB/s]
tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 350/350 [00:00<00:00, 4.86MB/s]
vocab.txt: 232kB [00:00, 85.2MB/s]
tokenizer.json: 466kB [00:00, 136MB/s]
special_tokens_map.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 1.99MB/s]
config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 1.36MB/s]
/opt/venv/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/opt/venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(
/opt/venv/lib/python3.11/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.
  warnings.warn(
Classification metadata saved.
>>> Extracting and poisoning data per concept...
>>> Extracting and poisoning data per concept...
---------------------------------------------
Processing concept: woman
Found 24 .p files → selecting 7
/opt/venv/lib/python3.11/site-packages/clip/clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging
100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 317MiB/s]
Traceback (most recent call last):
  File "/app/data_extraction.py", line 136, in <module>
    main()
  File "/app/data_extraction.py", line 92, in main
    cur_img = Image.fromarray(cur_data["img"])
                              ~~~~~~~~^^^^^^^
KeyError: 'img'


new error
abilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/unet.
Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.
Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  9.71it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 18.84it/s]
# Iter: 0       Loss: 833.500
# Iter: 50      Loss: 656.000
# Iter: 100     Loss: 649.000
# Iter: 150     Loss: 639.500
# Iter: 200     Loss: 625.000
# Iter: 250     Loss: 610.000
# Iter: 300     Loss: 590.000
# Iter: 350     Loss: 573.500
# Iter: 400     Loss: 554.500
# Iter: 450     Loss: 533.500
---------------------------------------------
Processing concept: sky
Found 25 .p files → selecting 3
/opt/venv/lib/python3.11/site-packages/clip/clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging
No candidates passed threshold; skipping selection.
Generating poisoned samples (target = tiger)...
/opt/venv/lib/python3.11/site-packages/diffusers/pipelines/pipeline_loading_utils.py:333: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1 via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1 currently does not have the required variant filenames in the 'main' branch. 
 The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1 is missing fp16 files' so that the correct variant file can be added.
  warnings.warn(
Loading pipeline components...:   0%|                                                                                                                                                                                                                               | 0/5 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/unet.
Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.
Loading pipeline components...:  40%|██████████████████████████████████████████████████████████████████████████████████████                                                                                                                                 | 2/5 [00:00<00:00,  8.80it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/vae.
Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.
`torch_dtype` is deprecated! Use `dtype` instead!
Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  9.63it/s]
---------------------------------------------
Processing concept: tree
---------------------------------------------
Processing concept: woman
Found 22 .p files → selecting 3
/opt/venv/lib/python3.11/site-packages/clip/clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging
No candidates passed threshold; skipping selection.
Generating poisoned samples (target = tiger)...
/opt/venv/lib/python3.11/site-packages/diffusers/pipelines/pipeline_loading_utils.py:333: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1 via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1 currently does not have the required variant filenames in the 'main' branch. 
 The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1 is missing fp16 files' so that the correct variant file can be added.
  warnings.warn(
Loading pipeline components...:   0%|                                                                                                                                                                                                                               | 0/5 [00:00<?, ?it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/unet.
Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.
Loading pipeline components...:  60%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 3/5 [00:00<00:00, 12.99it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/f7f33030acc57428be85fbec092c37a78231d75a/vae.
Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.
`torch_dtype` is deprecated! Use `dtype` instead!
Loading pipeline components...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  8.11it/s]
>>> Renaming and consolidating poisoned files...
mv: cannot stat '/app/Data/poisoned_output/sky/*.p': No such file or directory

###11/11/2025

██████████████████████████████████████████████████████████████████████████████████▌                        | 45/50 [00:02<00:00, 20.72it/ 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 48/50 [00:02<00:00, 20.72it/100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 20.72it/s]
# Iter: 0       Loss: 837.500
# Iter: 50      Loss: 677.000
# Iter: 100     Loss: 660.500
# Iter: 150     Loss: 643.500
# Iter: 200     Loss: 630.000
# Iter: 250     Loss: 607.000
# Iter: 300     Loss: 587.000
# Iter: 350     Loss: 561.500
# Iter: 400     Loss: 536.000
# Iter: 450     Loss: 513.500
---------------------------------------------
Processing concept: noise
Found 12 .p files → selecting 3
/opt/venv/lib/python3.11/site-packages/clip/clip.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging
Traceback (most recent call last):
  File "/app/data_extraction.py", line 136, in <module>
    main()
  File "/app/data_extraction.py", line 108, in main
    res = cosine_similarity(text_emb_np, text_emb_target_np).reshape(-1)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 1728, in cosine_similarity
    X, Y = check_pairwise_arrays(X, Y)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/sklearn/metrics/pairwise.py", line 200, in check_pairwise_arrays
    X = check_array(
        ^^^^^^^^^^^^
  File "/opt/venv/lib/python3.11/site-packages/sklearn/utils/validation.py", line 1128, in check_array
    raise ValueError(


increasing min cluster size helped and i need to skip the noise folder
